{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1aa25da-37b5-41a5-b755-0bedfd40d9fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction to Python for Environmental Science - Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705ab83-712a-4931-a4f5-00b58581c041",
   "metadata": {},
   "source": [
    "![JCEEI logo](../jceei_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6608bc-c353-4b09-88d4-fa4f8e610f6a",
   "metadata": {},
   "source": [
    "## Objectives of this session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f28550-40dd-4e11-b1ce-affa729eff36",
   "metadata": {},
   "source": [
    "- Awareness of the difference between tabular and gridded datasets\n",
    "- Understand how to load and manipulate data using NumPy\n",
    "- Understand of how to load and manipulate data using pandas \n",
    "- How to calculate summary statistics in both NumPy and pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518031e-0574-496b-a770-2e7579539f87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Key data types\n",
    "There are two core types of data that are commonly used in Environmental Science:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e848b5b-daa7-4e80-9977-27dd02524f87",
   "metadata": {},
   "source": [
    "### Tabular Data\n",
    "This is data in rows and columns, as you would expect to see in a spreadsheet.\n",
    " - Each row represents a data point e.g. e.g. each employee in a payroll system; each measurement time in a weather observation system\n",
    " - Each column represent a feature of the data point e.g. name, employee ID, department, salary in a payroll system; temperature, wind, sunshine in a weather observation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d96ea-a7c6-405f-ac2c-06c873906f1c",
   "metadata": {},
   "source": [
    "### Gridded Data\n",
    "A multi-dimensional array of data, reperesenting a regular grid of measurements.\n",
    " - This might be the output of a weather forecast model over the UK.\n",
    " - Dimensions could be latitude, longitude and time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a08278-2987-4dc1-ad68-28a983a8484d",
   "metadata": {},
   "source": [
    "This notebook will focus on tabular data, with gridded datasets and python tools for loading and working with gridded data being covered later in the session. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904ee2d-f8f9-47c4-91a4-d61da471dbfb",
   "metadata": {},
   "source": [
    "# Tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0cfe52-2427-4ef9-80fb-8b211f46ff96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24cba4-4d06-4356-81c1-4a845ea5313a",
   "metadata": {},
   "source": [
    "NumPy is the fundamental package for scientific computing with Python. Its primary purpose is to provide a powerful N-dimensional array object. Here will mainly focus on it's application to two dimensional data.\n",
    "\n",
    "### What is NumPy?\n",
    "\n",
    "NumPy: 'Numerical Python'\n",
    "\n",
    "- Open source Python library\n",
    "- A library of fast, precompiled functions \n",
    "- Efficient computation with multi-dimensional arrays\n",
    "\n",
    "To begin with let's import NumPy and check the version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f70aee-c94a-44e8-a9fb-c8e6bc822156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.3\n"
     ]
    }
   ],
   "source": [
    "# NumPy is often imported as np \n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00ff94-34a6-4e10-b7c8-13b2b208c111",
   "metadata": {},
   "source": [
    "### Documentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1feb8e7-f380-4759-bb49-6eae1ec7328c",
   "metadata": {},
   "source": [
    "Here is a link to the NumPy documentation for v1.23: https://numpy.org/doc/1.23/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e1402-9d11-4a57-9bca-a2d53e2aad7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating arrays in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ecf6e-c7c5-49e0-beb3-87829f8140cb",
   "metadata": {},
   "source": [
    "NumPy provides many different ways to create arrays. These are listed in the documentation at: https://numpy.org/doc/stable/user/basics.creation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31e88ed-f3ff-42d1-8ad9-10658a3bc02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "vals_arr = np.array(vals)\n",
    "vals_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbfca84-9def-4cc2-b6c0-bd396d1c28eb",
   "metadata": {},
   "source": [
    "NumPy arrays are containers of elements of the same *type* e.g. only integers. The type of an array can be determined with the attribute `dtype` and changed with the attribute `astype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a348c12f-9229-4d2b-ae84-723b709005a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e59f5b94-f8d5-4d8d-8ea1-feb6463b05ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_arr.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dcb122-76ac-4bf0-8edc-83effffb7103",
   "metadata": {},
   "source": [
    "We can create an array using `arange`, which returns a numpy array containing evenly spaced values within a given interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5b51ac-eefc-43cb-8d4f-832088dee4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71942625-0fef-4a3e-a221-1e21c569f90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a662fd7-17af-41f9-b4db-a3062b450895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2, 10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d102608-7eed-4ced-bfcc-3b3d4a112293",
   "metadata": {},
   "source": [
    "### Indexing arrays\n",
    "\n",
    "You can index NumPy arrays in the same way as other Python objects, by using square brackets `[]`. This means we can index to retrieve a single element, multiple consecutive elements, or a more complex sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab2fc38-433d-4205-abfc-0a7ac26762c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(1,7)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0179fb6-5510-4ef9-ba18-93a03bb22340",
   "metadata": {},
   "source": [
    "Indexing counts from zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71587fc-327e-44a9-a0fa-c98e8bbaacdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr[2] = 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"arr[2] = {arr[2]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5e4ba-0d4a-42ea-8a2a-0dcedcff7305",
   "metadata": {},
   "source": [
    "Starting and stopping index, up to and not include the stopping index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33409312-c927-48e8-bf4d-4fdf4e41223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr[2:5] = [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(f\"arr[2:5] = {arr[2:5]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e4b8a-53f0-4c0f-988c-0f13be3430d5",
   "metadata": {},
   "source": [
    "Start at first element, stop at last element, take every other element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b73af376-9ef3-4f61-9d4a-dcbdba7d3b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr[::2] = [1 3 5]\n"
     ]
    }
   ],
   "source": [
    "print(f\"arr[::2] = {arr[::2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9009a7-8b73-4c86-931b-946b2e329417",
   "metadata": {},
   "source": [
    "We can also index conditionally, based on the data in the array. \n",
    "\n",
    "You can pass in an array of True and False values (a boolean array), or, more commonly, a condition that returns a boolean array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d8eaa-b231-4b55-9b58-5e67444a502f",
   "metadata": {},
   "source": [
    "First of all, we create our condition and assign the output to the argument bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc6d950e-145e-4c25-8b19-b8e20775d57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False,  True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bools = arr % 2 == 0  # % operator give the remainder of the devision, when '% 2' the answer will always be 1 or 0\n",
    "bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df547c2-1e61-4760-8095-5239cb30a457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[bools]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a978341-fa35-4140-a100-489f6dd8acf4",
   "metadata": {},
   "source": [
    "### Multi-dimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be5eb2-2a64-49a7-a670-bc22957ed5f5",
   "metadata": {},
   "source": [
    "The multidimensional array object is at the core of all of NumPy's functionality. Let's explore this object some more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2adb13-36cd-43b8-b55d-008a392b47fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d8de3-3bc8-41fe-8715-db49e69fc8e6",
   "metadata": {},
   "source": [
    "We will use reshape to create our 2 dimensional array from our original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77dd7554-b9ec-4b03-845b-f529d952cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "arr_2d = arr.reshape(2,3)\n",
    "print(arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9af58-dab4-4cde-a2f0-bf781730672f",
   "metadata": {},
   "source": [
    "Lets explore some of the properties of this 2 dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf4eeedd-22c2-4498-913d-bd0919a3cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array shape: (2, 3)\n",
      "Array element dtype: int64\n",
      "Number of dimensions in arr: 2\n",
      "Number of elements in the array: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Array shape:\", arr_2d.shape)\n",
    "print(\"Array element dtype:\", arr_2d.dtype)\n",
    "print('Number of dimensions in arr:', arr_2d.ndim)\n",
    "print('Number of elements in the array:', arr_2d.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b8f25-c008-4fae-a78a-7d506a40b9e6",
   "metadata": {},
   "source": [
    "We can also transpose the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5960c77-55d6-4a23-a78a-63d2fc9bdd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed array:\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "Shape of transposed array: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Transposed array:')\n",
    "print(arr_2d.T)\n",
    "print('Shape of transposed array:', arr_2d.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f3d63-ecbf-4a91-980a-6348c157efdb",
   "metadata": {},
   "source": [
    "### Arthimetic and Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46600b-6b40-4018-b264-9bd56446b2fd",
   "metadata": {},
   "source": [
    "You can use NumPy to perform arithmetic operations between two arrays in an element-by-element fashion. this applies for all of the basic Python mathematical operators (i.e. `+`, `-`, `*`, `/`, `//`, `%`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215e2898-2882-4c6d-a433-c68212acf95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1: [0 1 2 3 4]\n",
      "Array 2: [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.arange(5)\n",
    "arr2 = np.arange(5)\n",
    "print('Array 1:', arr1)\n",
    "print('Array 2:', arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b18755a3-13e8-4cf6-8e67-b9be1627e97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] + [0 1 2 3 4] = [0 2 4 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(f'{arr1} + {arr2} = {arr1 + arr2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "066dcf70-52ec-46b4-9d38-413d6cef3716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] - [0 1 2 3 4] = [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f'{arr1} - {arr2} = {arr1 - arr2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d1309d4-2302-4038-a0a7-77328e638c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] * [0 1 2 3 4] = [ 0  1  4  9 16]\n"
     ]
    }
   ],
   "source": [
    "print(f'{arr1} * {arr2} = {arr1 * arr2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01d2a1-8f3a-41a7-8b1a-4d2fce765273",
   "metadata": {},
   "source": [
    "### Broadcasting \n",
    "\n",
    "There are times when you need to perform calculations between NumPy arrays of different sizes.\n",
    "\n",
    "For example, suppose you have maximum temperatures from each of three recording stations, recorded on two separate days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd12520b-05fc-4553-9554-51b8d070d7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data:\n",
      "[[12 14 11]\n",
      " [11 12 15]]\n"
     ]
    }
   ],
   "source": [
    "daily_records = np.array([[12, 14, 11], [11, 12, 15]])\n",
    "\n",
    "print('raw data:')\n",
    "print(daily_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ffc752-34da-41cb-bb9f-c7bfbb3369a7",
   "metadata": {},
   "source": [
    "Each station is known to overstate the maximum recorded temperature by a different known constant value. You wish to subtract the appropriate offset from each station's values.\n",
    "\n",
    "You can do that like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ea9e380-83e1-44b2-a166-b795dcdc0952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected values:\n",
      "[[10 13  7]\n",
      " [ 9 11 11]]\n"
     ]
    }
   ],
   "source": [
    "offset = np.array([2, 1, 4])\n",
    "\n",
    "corrected_records = daily_records - offset\n",
    "\n",
    "print('corrected values:')\n",
    "print(corrected_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0a991-85e4-4a93-90e7-04c77a384a1b",
   "metadata": {},
   "source": [
    "NumPy allows you to do this easily using a powerful piece of functionality called **broadcasting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77948e52-818e-4ce3-8e5a-449dd6a95c6a",
   "metadata": {},
   "source": [
    "Broadcasting is a way of treating the arrays ***as if*** they had the same dimensions, and thus have elements all corresponding.  It is then easy to perform the calculation, element-wise.  \n",
    "It does this by matching dimensions in one array to the other where possible, and using repeated values where there is no corresponding dimension in the other array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ed35f-146c-4618-a97b-0f665a16dac7",
   "metadata": {},
   "source": [
    "### Rules of Broadcasting \n",
    "\n",
    "Broadcasting applies these three rules:\n",
    "\n",
    "1.    If the two arrays differ in their number of dimensions, the shape of the array with fewer dimensions is padded with ones on its leading (left) side.\n",
    "\n",
    "1.    If the shape of the two arrays does not match in any dimension, either array with shape equal to 1 in a given dimension is stretched to match the other shape.\n",
    "\n",
    "1.    If in any dimension the sizes disagree and neither has shape equal to 1, an error is raised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8261416d-c3c6-4b30-85fb-5240b6d7628d",
   "metadata": {},
   "source": [
    "### Loading data with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49721d-5802-4897-9340-b86bb03fce8e",
   "metadata": {},
   "source": [
    "As well as creating arrays in NumPy, we can also load data into NumPy arrays from files. NumPy supports loading data from text files e.g. txt or csv file formats, which are commonly used to store tabular datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bfc192e-324a-4cc3-aad8-c7f4c5bee4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_arr = np.loadtxt('weather.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcee1bdd-a212-4f6d-a4f5-8f610002e6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4e+03 2.1e+01 2.0e+00 0.0e+00]\n",
      " [1.5e+03 2.4e+01 5.0e+00 0.0e+00]\n",
      " [1.6e+03 2.0e+01 1.5e+01 1.0e+00]\n",
      " [1.7e+03 2.2e+01 5.0e+00 1.5e+01]\n",
      " [1.8e+03 2.1e+01 1.0e+00 0.0e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(weather_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e9be2c8-abff-46cb-a978-8395e2902c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array shape: (5, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Array shape:', weather_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa99a7-00ee-4617-a12a-54c7ad5b29de",
   "metadata": {},
   "source": [
    "We are able to select data in different rows and columns in this array using indexing. So for example, we can select the first two rows of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "374d85db-b695-4f15-b683-014eed6aaef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1400.,   21.,    2.,    0.],\n",
       "       [1500.,   24.,    5.,    0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_arr[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b8e15-f149-4335-9e1f-4e54fe4eff58",
   "metadata": {},
   "source": [
    "However, as there are no labels for the data, if we want to select the time column for example, we need to refer back to the original dataset and check which column time data is in before indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b11fcbe-4ca2-45d7-82c4-522820db8391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1400., 1500., 1600., 1700., 1800.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_arr[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455243b3-a796-4599-8677-477e8cfdb4fc",
   "metadata": {},
   "source": [
    "### Concatenation - combining multiple arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128a092-30d0-4f40-bcab-656145ff07e6",
   "metadata": {},
   "source": [
    "We can combine multiple NumPy arrays using concatentation. The arrays must have the same shape except in the dimension corresponding to the axis along which the arrays are joined.\n",
    "\n",
    "For example, if we compare the shape of `weather_arr` and `weather_arr2`, they both have 5 rows, but `weather_arr` has 4 columns and `weather_arr2` only has 3. So if we try to concatenate these two arrays based on columns (in NumPy terms with axis=0, this is the default), we will get an error as there is a different number of columns (Exercise: give this a try!). However, we can concatenate these two based on rows (axis=1), as both arrays have 5 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06ebfd7d-f9a4-4776-8e0b-d270494267ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b36f17b-9a83-4377-98c6-24da79d90100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_arr2 = np.loadtxt('weather2.csv', delimiter=',', skiprows=1)\n",
    "weather_arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4578d4c6-7261-407b-bbc7-ace9cd971172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.400e+03, 2.100e+01, 2.000e+00, 0.000e+00, 1.400e+03, 1.700e+01,\n",
       "        1.007e+03],\n",
       "       [1.500e+03, 2.400e+01, 5.000e+00, 0.000e+00, 1.500e+03, 1.900e+01,\n",
       "        1.005e+03],\n",
       "       [1.600e+03, 2.000e+01, 1.500e+01, 1.000e+00, 1.600e+03, 2.000e+01,\n",
       "        1.003e+03],\n",
       "       [1.700e+03, 2.200e+01, 5.000e+00, 1.500e+01, 1.700e+03, 1.800e+01,\n",
       "        1.006e+03],\n",
       "       [1.800e+03, 2.100e+01, 1.000e+00, 0.000e+00, 1.800e+03, 1.700e+01,\n",
       "        1.008e+03]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_arr = np.concatenate([weather_arr, weather_arr2], axis=1)\n",
    "combined_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "950caffd-97dc-4f33-81d6-d9b3ff9b4cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54ee6d-ca93-4ae7-bba5-93fb926ddd5b",
   "metadata": {},
   "source": [
    "Note that the time column, which was the same in both datasets, has been duplicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5da11-abb6-43a9-84ba-02db01f0f8e6",
   "metadata": {},
   "source": [
    "### Calculating summary statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c810eb6-1191-46da-b9c6-c71892638f39",
   "metadata": {},
   "source": [
    "NumPy arrays support many common statistical calculations. For a list of common operations, see: https://numpy.org/doc/stable/reference/routines.statistics.html.\n",
    "\n",
    "The simplest operations consist of calculating a single statistical value from an array of numbers,e.g. a mean value, a variance or a minimum.\n",
    "\n",
    "Let's calculate these for the temperature column in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a73d505-1409-4f22-bbb1-f6976a244f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21., 24., 20., 22., 21.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = weather_arr[:, 1]\n",
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f48e4d9-8098-4146-b660-0cf29767c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum temperature =  20.0\n",
      "Maximum temperature =  24.0\n"
     ]
    }
   ],
   "source": [
    "print('Minimum temperature = ', np.min(temperature))\n",
    "print('Maximum temperature = ', np.max(temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcb6a87a-1827-41fe-b684-4ccb63d4f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean temperature =  21.6\n",
      "Median temperature =  21.0\n"
     ]
    }
   ],
   "source": [
    "print('Mean temperature = ', np.mean(temperature))\n",
    "print('Median temperature = ', np.median(temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83da35ae-01cf-4f37-9373-a084b1f5e98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation =  1.3564659966250536\n",
      "Variance =  1.8399999999999999\n"
     ]
    }
   ],
   "source": [
    "print('Standard deviation = ', np.std(temperature))\n",
    "print('Variance = ', np.var(temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3a651-a3a8-4754-b7bf-384ba34c99fe",
   "metadata": {},
   "source": [
    "Used without any further arguments, statistical functions simply reduce the whole array to a single value.  In practice, however, we very often want to calculate statistics over only *some* of the dimensions.\n",
    "\n",
    "The most common requirement is to calculate a statistic along a single array dimension, while leaving all the other dimensions intact.   This is referred to as \"collapsing\" or \"reducing\" the chosen dimension.\n",
    "\n",
    "This is done by adding an \"axis\" keyword specifying which dimension, such as `np.min(data, axis=1)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f82b13c-5a55-4a85-aeb1-470b2bd7a4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value in each column =  [1.4e+03 2.0e+01 1.0e+00 0.0e+00]\n"
     ]
    }
   ],
   "source": [
    "print('Minimum value in each column = ', np.min(weather_arr, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc3ef7-ec15-45d6-9fca-4a30f69e069e",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68969fcb-ce5e-4c82-b60d-3dba5a6aad32",
   "metadata": {},
   "source": [
    "While NumPy is a useful tool, we have already seen a couple of things that make data analysis more challenging e.g. not explicitly having metadata (column names) for our dataset when we load data from a csv file, meaning it can be difficult to keep track of what the values represent. \n",
    "\n",
    "Pandas is another open source Python library, which is commonly used for data manipulation and analysis of tabular datasets.\n",
    "\n",
    "Let's start by importing pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14b4cec6-2216-4bc0-ad33-7faf1b6d906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "# Pandas is often imported as pd \n",
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e8e36-1352-4d4c-a0c1-fcf70c1a3992",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "\n",
    "Here is a link to the Pandas documentation for v1.5: https://pandas.pydata.org/pandas-docs/version/1.5/user_guide/index.html#user-guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaaa87f-1db0-429f-9a01-de16529995dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading tabular data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd276f-15f3-4fb6-8637-96cc9d4929a2",
   "metadata": {},
   "source": [
    "A DataFrame is the standard object for working with tabular data in Python. This provides an intuitive way to access and manipulate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f248b56-07b5-4ddf-b45d-3d93e6a661d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1700</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1800</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  temperature  wind  rain\n",
       "0  1400           21     2     0\n",
       "1  1500           24     5     0\n",
       "2  1600           20    15     1\n",
       "3  1700           22     5    15\n",
       "4  1800           21     1     0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv('weather.csv')\n",
    "print(type(weather_df))\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678aa36-e519-4a12-9a79-6ea8e7a2c7d1",
   "metadata": {},
   "source": [
    "Now that we have loaded a tabular data into Pandas, we can apply some common operations used for data analysis. Hopefully you'll see that these are more intuitive, and often require less code than when implemented manually.\n",
    "\n",
    "Perhaps the most important advantage of using a library such as Pandas is that it has been optimised for large tabular datasets, and so will usually perform better than manual python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81349bbc-8bdc-4f1e-9f03-0db72cbc28e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indexing and subsetting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01217f-ec18-4838-91b5-268107e0cac3",
   "metadata": {},
   "source": [
    "We might start by selecting data from a particular column of our dataset. Pandas allows us to select data from a column based on the name of the column, meaning we don't have to keep refering back to the original data file (as we did with NumPy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79f756d5-5682-45fc-ad12-ad9314707f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21\n",
       "1    24\n",
       "2    20\n",
       "3    22\n",
       "4    21\n",
       "Name: temperature, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df['temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82073d5f-ba8d-4f5c-9c25-664982f91a1a",
   "metadata": {},
   "source": [
    "It is also possible to select multiple columns, which is simple done by providing the column names to be selected within a list, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4f16137-897c-49d5-826f-e445d269c4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  rain\n",
       "0           21     0\n",
       "1           24     0\n",
       "2           20     1\n",
       "3           22    15\n",
       "4           21     0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[['temperature', 'rain']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a3c66-1f98-4ccf-b170-0134b52feba9",
   "metadata": {},
   "source": [
    "Warning, traditional indexing does not work with Pandas DataFrame. As you see below, we get an error when we try to select the first row of the dataframe using indexing. \n",
    "\n",
    "Instead, we use the `.loc` and `.iloc` functionality in pandas, `.iloc` selects a row based on the index and `.loc` select a row based on the index value. \n",
    "\n",
    "Note: these two will return the same result if the default index is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64d4f0aa-1688-4d4f-9adb-e23981140936",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/data/users/hbrown/conda/envs/spaceapps-mo-python-envsci/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/data/users/hbrown/conda/envs/spaceapps-mo-python-envsci/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/users/hbrown/conda/envs/spaceapps-mo-python-envsci/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mweather_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/data/users/hbrown/conda/envs/spaceapps-mo-python-envsci/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/data/users/hbrown/conda/envs/spaceapps-mo-python-envsci/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "weather_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259415f-4217-47fd-9faf-1fbb89b29b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28502b-c5e7-452a-8a9b-c513ee4ab20a",
   "metadata": {},
   "source": [
    "Similair to conditional indexing that we discussed earlier, we can select rows of a DataFrame based on the values in a certain column. \n",
    "\n",
    "Let's select rows in our DataFrame, where the value in the temperature column is greater than 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9098fe5-5335-49f1-ad01-422f3c086f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[weather_df['temperature']>21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c53c97-8773-4ec1-82b8-2b9df956041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111c9fd-4379-4ab6-a2c8-fa2db2775b80",
   "metadata": {},
   "source": [
    "Exercise: Try selecting the subset of our data when wind is greater than 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d5145-8e5a-4f57-a1ff-7d3c3a2bdfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3195e2f4-2656-4a91-8cae-44637ed12611",
   "metadata": {},
   "source": [
    "### Combining dataframes\n",
    "\n",
    "Pandas has some nice documentation explaining the different ways you can combine a dataset: https://pandas.pydata.org/docs/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316c8a8-14f1-4ab0-a9b9-62f70cb9b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df2 = pd.read_csv('weather2.csv')\n",
    "weather_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a7ac4-3374-4060-aa16-73c47de879cc",
   "metadata": {},
   "source": [
    "As with NumPy, pandas has functionality to concatenate multiple DataFrame. The advantage of pandas is that rather than just returning an error when the shape of two arrays is different, it will try to handle and where necessary fill any missing data with `NaN` values ('Not a Number'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebdd2d-891e-435d-b06d-f78861e04491",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([weather_df, weather_df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524f985-aa56-4796-9f2c-07452821d432",
   "metadata": {},
   "source": [
    "This however, is still not doing exactly what we want. We want the returned DataFrame to contain our five timesteps with columns for the five different weather variables. \n",
    "\n",
    "As with NumPy, we can define the axis to join over, which gets us close to what we want, but as we had before with NumPy, the time column in our DataFrame is duplicated, which we don't want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12010ab5-0169-45a0-a334-61e6a177710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([weather_df, weather_df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb64114-e4c4-4350-bba6-575f14f0d541",
   "metadata": {},
   "source": [
    "Pandas offers other ways to combine datasets. One of these options is to `merge`, which allows us to merge DataFrame objects with a database-style join. We can either select to join based on certain columns by name, or using the DataFrame index. \n",
    "\n",
    "Here we are merging `weather_df` and `weather_df2` based on the 'time' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257f18d-fdc9-4a69-8bca-e64a7347e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_weather_df = pd.merge(weather_df, weather_df2, right_on='time', left_on='time')\n",
    "combined_weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92046650-61ea-4970-bdf1-3cf6c95b53d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa474c-a110-49ec-ad30-74298e44db78",
   "metadata": {},
   "source": [
    "Pandas has functionality to calculate all of the summary statistics that we calculated with NumPy directly from the pandas DataFrame.\n",
    "\n",
    "Let's calculate some summary statistics for the temperature column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda75acd-c695-42c9-a231-144314fa6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = combined_weather_df['temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d3412-564c-4105-b665-8c5107264e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum temperature = ', temperature.min())\n",
    "print('Maximum temperature = ', temperature.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e2b0f-ae96-4df3-90dc-1bb0e078fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean temperature = ', temperature.mean())\n",
    "print('Median temperature = ', temperature.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816bf52-5214-47cf-a33e-77df74246e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Standard deviation = ', temperature.std())\n",
    "print('Variance = ', temperature.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b306b2-d2f5-4cfa-9dd1-c0c193e1e306",
   "metadata": {},
   "source": [
    "We can also calculate statistics for all columns at once by applying the functions to the DataFrame. For example, we can calculate the mean value for every column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d604a9-d71d-496a-a665-7a29af3b3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_weather_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb340a70-b439-4df1-81f2-24db5ba0bf86",
   "metadata": {},
   "source": [
    "Finally, the pandas `describe` function is useful for getting an overview of the entire dataset, calculating a number of useful summary statistics at once including the mean, standard deviation and interquartile range of the data in the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa719e-042b-40fe-ba16-2b0a8ca2a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_weather_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdaca7e-f48a-45c4-bc63-a57e919af6e3",
   "metadata": {},
   "source": [
    "### Advantages of pandas\n",
    "Having looked at how one can use Pandas to handle data, what are the advantages of using this third-party library over writing code in python yourself to do the same operations?\n",
    "- You spend less time writing boilerplate code and more tieme focusing on what is unique to your data or problem\n",
    "- The code in pandas has been written and optimised by performance specialists and will certainly be more efficient than a first attempt at the same operation in python\n",
    "- Coding using the pandas interface opens the possibility of working easily and interchangeably with other libraries such as dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a4078-c524-449b-92c2-04d607df4f18",
   "metadata": {},
   "source": [
    "## Other useful material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3901daa-ba8c-4865-a469-baf48daaf6d9",
   "metadata": {},
   "source": [
    "- SciPy lectures for NumPy: http://scipy-lectures.org/intro/numpy/index.html\n",
    "- Pandas tutorials: https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbacbf9-114a-48da-b1e4-ecd6fa975a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
